import streamlit as st
import pandas as pd
import google.generativeai as genai
import altair as alt
from datetime import datetime
import json

# --- CONFIGURAÃ‡ÃƒO DA PÃGINA E API ---
st.set_page_config(
    page_title="Assistente Lidera Assessments",
    page_icon="ğŸ“Š",
    layout="wide"
)

try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel('gemini-1.5-flash')
    gemini_configurado = True
except Exception:
    gemini_configurado = False

# --- FUNÃ‡Ã•ES DE LÃ“GICA DE ANÃLISE (A maioria sem alteraÃ§Ãµes) ---
def classificar_esforco(valor_adaptacao):
    if valor_adaptacao <= 1.0: return "Baixo esforÃ§o de adaptaÃ§Ã£o"
    if 1.0 < valor_adaptacao <= 2.0: return "EsforÃ§o de adaptaÃ§Ã£o moderado"
    if 2.0 < valor_adaptacao <= 2.9: return "EsforÃ§o de adaptaÃ§Ã£o moderado alto"
    if valor_adaptacao >= 3.0: return "Potencial estresse"
    return "Indefinido"

def analisar_disc(dados_df):
    resultados = {}
    fatores_disc = ["Dominador", "Influenciador", "Estabilidade", "Conformidade"]
    for fator in fatores_disc:
        coluna_natural, coluna_work = f"{fator} Natural", f"{fator} Work"
        if coluna_natural in dados_df.columns and coluna_work in dados_df.columns:
            natural_val = pd.to_numeric(dados_df[coluna_natural].iloc[0], errors='coerce')
            work_val = pd.to_numeric(dados_df[coluna_work].iloc[0], errors='coerce')
            if pd.notna(natural_val) and pd.notna(work_val):
                adaptacao = abs(work_val - natural_val)
                resultados[fator] = { "Natural": natural_val, "Adaptado": work_val, "AdaptaÃ§Ã£o": adaptacao, "NÃ­vel de EsforÃ§o": classificar_esforco(adaptacao) }
    return resultados

def criar_grafico_disc(dados_analise_disc):
    dados_grafico = []
    for fator, valores in dados_analise_disc.items():
        dados_grafico.append({"Fator": fator, "Tipo de Perfil": "Natural", "PontuaÃ§Ã£o": valores["Natural"]})
        dados_grafico.append({"Fator": fator, "Tipo de Perfil": "Adaptado", "PontuaÃ§Ã£o": valores["Adaptado"]})
    df_grafico = pd.DataFrame(dados_grafico)
    grafico = alt.Chart(df_grafico).mark_bar(cornerRadiusTopLeft=3, cornerRadiusTopRight=3).encode(
        x=alt.X('Fator:N', title='Fator DISC', sort=None, axis=alt.Axis(labelAngle=0)),
        y=alt.Y('PontuaÃ§Ã£o:Q', title='PontuaÃ§Ã£o'),
        color=alt.Color('Tipo de Perfil:N', title='Tipo de Perfil', scale=alt.Scale(range=['#2A70B8', '#FF4B4B'])),
        xOffset='Tipo de Perfil:N'
    ).properties(title='Comparativo de Perfis DISC: Natural vs. Adaptado')
    return grafico

# --- CORREÃ‡ÃƒO: FunÃ§Ã£o de relatÃ³rio agora pede e processa JSON ---
def gerar_relatorio_final(dados_df):
    with st.spinner('Analisando dados e consultando a IA...'):
        analise_disc_data = analisar_disc(dados_df)
        resumo_para_ia = f"**AnÃ¡lise Comportamental (DISC):** {analise_disc_data}"
        
        prompt_final = f"""
        Aja como o Assistente de AnÃ¡lise Virtual da Lidera Assessments. Sua tarefa Ã© gerar o conteÃºdo para um relatÃ³rio de anÃ¡lise combinada.
        **Sua resposta deve ser OBRIGATORIAMENTE um objeto JSON vÃ¡lido.**
        O JSON deve ter chaves para cada um dos 12 itens do relatÃ³rio. O valor de cada chave deve ser o texto correspondente para aquela seÃ§Ã£o.
        Use os dados estruturados fornecidos para elaborar o conteÃºdo de cada seÃ§Ã£o.
        REGRAS: Refira-se ao indivÃ­duo sempre como "O(A) Avaliado(a)". Substitua "scores" por "pontuaÃ§Ãµes".

        DADOS ESTRUTURADOS PARA ANÃLISE:
        {resumo_para_ia}

        ESTRUTURA JSON OBRIGATÃ“RIA (preencha os valores):
        {{
          "objetivo_analise": "...",
          "data_avaliacao": "{datetime.now().strftime('%d/%m/%Y')}",
          "dados_considerados": "...",
          "profissoes_compativeis": "...",
          "parecer_geral": "...",
          "correspondencia_cargo": "...",
          "vantagens_fortes": "...",
          "oportunidades_melhoria": "...",
          "analise_disc": "...",
          "analise_vieses": "Dados nÃ£o fornecidos para esta anÃ¡lise.",
          "analise_qp": "Dados nÃ£o fornecidos para esta anÃ¡lise.",
          "importante": "Em resumo, a anÃ¡lise combinada destas avaliaÃ§Ãµes, embora valiosa, exige uma abordagem cautelosa e multifacetada..."
        }}
        """
        try:
            response = model.generate_content(prompt_final)
            # Limpa e parseia a resposta JSON da IA
            json_text = response.text.strip().replace("```json", "").replace("```", "")
            report_data = json.loads(json_text)
            return report_data, analise_disc_data
        except (json.JSONDecodeError, Exception) as e:
            st.error(f"Houve um erro ao processar a resposta da IA. Detalhes: {e}")
            st.text_area("Resposta bruta da IA", response.text)
            return None, None

def responder_chat(pergunta, relatorio_gerado_dict, dados_pessoa):
    # Converte o dicionÃ¡rio do relatÃ³rio em texto para o contexto
    relatorio_texto = "\n".join([f"**{key.replace('_', ' ').title()}**: {value}" for key, value in relatorio_gerado_dict.items()])
    base_conhecimento = f"""
    CONTEXTO PRINCIPAL: O RELATÃ“RIO GERADO
    ---
    {relatorio_texto}
    ---
    REGRAS DE ANÃLISE: A "AdaptaÃ§Ã£o" DISC Ã© a diferenÃ§a absoluta entre Natural e Adaptado. > 3.0 Ã© "Potencial estresse".
    DADOS BRUTOS:
    {dados_pessoa.to_string()}
    """
    prompt_chat = f"""
    VocÃª Ã© um assistente especialista que ajuda a interpretar um relatÃ³rio de avaliaÃ§Ã£o.
    Sua fonte primÃ¡ria de conhecimento Ã© o contexto fornecido. Priorize respostas baseadas nele.
    Para saudaÃ§Ãµes ou perguntas gerais, responda de forma amigÃ¡vel e concisa.

    Base de Conhecimento: {base_conhecimento}
    Pergunta do UsuÃ¡rio: "{pergunta}"
    Sua Resposta:
    """
    try:
        response = model.generate_content(prompt_chat)
        return response.text
    except Exception as e:
        return f"Ocorreu um erro na IA do chat: {e}"

# --- INTERFACE GRÃFICA (UI) FINAL ---

st.title("Assistente de AnÃ¡lise Virtual Personalizado")
st.caption("Lidera AssessmentsÂ®")

# CORREÃ‡ÃƒO: Injeta CSS para o layout do chat
st.markdown("""
<style>
    .chat-container {
        display: flex;
        flex-direction: column;
    }
    .chat-message {
        padding: 0.75rem;
        border-radius: 0.5rem;
        margin-bottom: 0.5rem;
        max-width: 100%;
        word-wrap: break-word;
    }
    .user-message {
        background-color: #fce8cc;
        align-self: flex-end;
    }
    .assistant-message {
        background-color: #fcf3e6;
        align-self: flex-start;
    }
    .st-expander > div:first-child > div:first-child p {
    font-weight: bold !important;
    font-size: 2em !important; /* Aumenta em 10% */
    }        
</style>
""", unsafe_allow_html=True)


if 'analise_completa' not in st.session_state:
    st.session_state.analise_completa = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

uploaded_file = st.file_uploader("Para comeÃ§ar, carregue o arquivo CSV com os dados da avaliaÃ§Ã£o", type=["csv"])

if uploaded_file is not None:
    dados_brutos = pd.read_csv(uploaded_file)
    st.markdown("---")
    st.subheader("SeleÃ§Ã£o de Perfil")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        pessoa_selecionada = st.selectbox("Escolha o perfil para analisar", options=dados_brutos['Assessment Taker Name'].unique())
    with col2:
        analyze_button = st.button("Gerar RelatÃ³rio ğŸ“ˆ", type="primary", use_container_width=True, disabled=not gemini_configurado)

    if analyze_button:
        dados_pessoa = dados_brutos[dados_brutos['Assessment Taker Name'] == pessoa_selecionada]
        if not dados_pessoa.empty:
            report_data_dict, analise_disc_detalhada = gerar_relatorio_final(dados_pessoa)
            if report_data_dict:
                st.session_state.analise_completa = {
                    "relatorio_dict": report_data_dict,
                    "grafico_disc_data": analise_disc_detalhada,
                    "dados_pessoa": dados_pessoa
                }
                st.session_state.chat_history = [{
                    "role": "assistant",
                    "content": "OlÃ¡! O relatÃ³rio foi gerado. Use o chat abaixo para tirar dÃºvidas sobre os resultados."
                }]
        else:
            st.error("NÃ£o foi possÃ­vel encontrar os dados para a pessoa selecionada.")
            st.session_state.analise_completa = None

if st.session_state.analise_completa:
    st.markdown("---")
    st.header(f"Resultados da AnÃ¡lise para: {st.session_state.analise_completa['dados_pessoa']['Assessment Taker Name'].iloc[0]}")
    
    report_dict = st.session_state.analise_completa["relatorio_dict"]
    
    # 1. RelatÃ³rio Formatado com Expanders
    st.subheader("ğŸ“„ RelatÃ³rio Completo")
    titulos = {
        "objetivo_analise": "ğŸ¯ Objetivo da AnÃ¡lise", "data_avaliacao": "ğŸ“… Data da AvaliaÃ§Ã£o Mais Recente",
        "dados_considerados": "ğŸ—‚ï¸ Dados Considerados", "profissoes_compativeis": "ğŸš€ Potenciais ProfissÃµes CompatÃ­veis",
        "parecer_geral": "ğŸ’¡ Parecer Geral da AnÃ¡lise", "correspondencia_cargo": "ğŸ‘” NÃ­vel de CorrespondÃªncia com o Cargo",
        "vantagens_fortes": "ğŸŒŸ Vantagens e Pontos Fortes", "oportunidades_melhoria": "ğŸŒ± Oportunidades de Melhoria",
        "analise_disc": "ğŸ”„ AnÃ¡lise de Estresse e AdaptaÃ§Ã£o DISC", "analise_vieses": "ğŸ” AnÃ¡lise de Vieses",
        "analise_qp": "ğŸ§  AnÃ¡lise de QP e Sabotadores", "importante": "â— Importante"
    }
    for key, titulo in titulos.items():
        with st.expander(titulo, expanded=True):
            st.markdown(report_dict.get(key, "NÃ£o disponÃ­vel."))
    
    st.markdown("---")

    # 2. GrÃ¡fico
    st.subheader("ğŸ“Š AnÃ¡lise GrÃ¡fica")
    if st.session_state.analise_completa["grafico_disc_data"]:
        grafico = criar_grafico_disc(st.session_state.analise_completa["grafico_disc_data"])
        st.altair_chart(grafico, use_container_width=True)
    
    st.markdown("---")

    # 3. Chat Interativo
    st.subheader("ğŸ’¬ Converse com a IA sobre este RelatÃ³rio")

    chat_container = st.container(height=400)
    with chat_container:
        st.markdown('<div class="chat-container">', unsafe_allow_html=True)
        for message in st.session_state.chat_history:
            role_class = "user-message" if message["role"] == "user" else "assistant-message"
            st.markdown(f'<div class="chat-message {role_class}">{message["content"]}</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

if st.session_state.analise_completa:
    if prompt := st.chat_input("FaÃ§a uma pergunta sobre o relatÃ³rio..."):
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        response = responder_chat(
            prompt, 
            st.session_state.analise_completa["relatorio_dict"], 
            st.session_state.analise_completa["dados_pessoa"]
        )
        st.session_state.chat_history.append({"role": "assistant", "content": response})
        st.rerun()

if not gemini_configurado:
    st.warning("A funcionalidade de IA estÃ¡ desabilitada. Configure a chave de API para prosseguir.")